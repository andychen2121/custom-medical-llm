{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14abc76c-a9f1-4bc7-b88a-760bf8096a3f",
   "metadata": {},
   "source": [
    "# Custom Medical VQA Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b4bfe2-fce0-4702-a803-01db9dcab7eb",
   "metadata": {},
   "source": [
    "### Goal: \n",
    "Using pre-trained LLM and scraped caption : image dataset, train a VQA model to accurately answer questions based on medical textbook. Explore whether an encoder or decoder model is more appropriate.\n",
    "\n",
    "### Textbook Source:\n",
    "https://drive.google.com/drive/u/2/folders/12mL45XMDRSxhkgMH_PIeQAAsAtbv-X2W\n",
    "\n",
    "### TODO:\n",
    "- form {text:image pairings} from scraped dictionary using coordinate classifier\n",
    "- vision + text modalities: use LLM for text and ??? (resnet CV) for image modality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84b07d7-2402-4b93-92a3-fc3f6c50d419",
   "metadata": {},
   "source": [
    "### Text & Image Pairing + Data Intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ecf39-e703-4a9d-a356-cba2e4cf13a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3b5a871-8460-404a-b3cc-3a8e9a6911a3",
   "metadata": {},
   "source": [
    "### Text & Vision Modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94647f3e-c407-48ce-b950-79fe3ee9138e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
